# -*- coding: utf-8 -*-
"""generalize_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/143SedNWT0g9Je1U9dZG-8oNPHokyoYpm
"""

import os 
import zipfile 
import tensorflow as tf 
from tensorflow.keras.preprocessing.image import ImageDataGenerator 
from tensorflow.keras import layers 
from tensorflow.keras import Model 
import matplotlib.pyplot as plt

import numpy as np
import os
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

# import the libraries as shown below

from tensorflow.keras.layers import Input, Lambda, Dense, Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential
import numpy as np
from glob import glob
#import matplotlib.pyplot as plt

local_zip = '/content/drive/MyDrive/airlab.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.models import Sequential
from keras.layers.pooling import GlobalAveragePooling2D
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from sklearn.model_selection import train_test_split 
from sklearn import metrics

import pandas as pd
import os
import numpy as np
import matplotlib.pyplot as plt

pip install split-folders[full]

import splitfolders
input_folder = '/content/airlab/2DS_rospla'
#input_folder = '/content/airlab/HVPS'

splitfolders.ratio(input_folder, output='2DS_rospla', seed=42, ratio=(.7, .2, .1), group_prefix=None)


#splitfolders.ratio(input_folder, output='HVPS', seed=42, ratio=(.7, .2, .1), group_prefix=None)

# re-size all the images to this
IMAGE_SIZE = [224, 224]

train_data_path = '/content/2DS_rospla/train'
valid_data_path = '/content/2DS_rospla/val'
test_data_path = '/content/2DS_rospla/test'


#train_data_path = '/content/HVPS/train'
#valid_data_path = '/content/HVPS/val'
#test_data_path = '/content/HVPS/test'

# Define Input Parameters
shape = (224, 224)
channel = (3, )
input_size = shape + channel

#batch size
batch_size = 32

train_datagen = ImageDataGenerator(rescale = 1./255, 
                                 rotation_range = 30, 
                                 width_shift_range = 0.2,
                                 height_shift_range = 0.2,
                                 zoom_range = 0.2,
                                 horizontal_flip = True)

test_datagen =  ImageDataGenerator(rescale = 1. / 255,
                                  horizontal_flip = True)

train_gen = train_datagen.flow_from_directory('/content/HVPS/train',
                                            target_size = shape,
                                            batch_size = batch_size,
                                            class_mode = 'categorical',
                                            shuffle = True)

val_gen = test_datagen.flow_from_directory('/content/HVPS/val',
                                          target_size = shape,
                                          batch_size = batch_size,
                                          class_mode = 'categorical',
                                          shuffle = False)

test_gen= test_datagen.flow_from_directory('/content/HVPS/test/',
                                          target_size = shape,
                                          batch_size = batch_size,
                                          class_mode = 'categorical',
                                          shuffle = False)

"""Using the below codes of line for 2D-S arumentaion"""

train_datagen = ImageDataGenerator(rescale = 1./255, 
                                 rotation_range = 30, 
                                 width_shift_range = 0.2,
                                 height_shift_range = 0.2,
                                 zoom_range = 0.2,
                                 horizontal_flip = True)

test_datagen =  ImageDataGenerator(rescale = 1. / 255,
                                  horizontal_flip = True)

train_gen = train_datagen.flow_from_directory('/content/2DS_rospla/train/',
                                            target_size = shape,
                                            batch_size = batch_size,
                                            class_mode = 'categorical',
                                            shuffle = True)

val_gen = test_datagen.flow_from_directory('/content/2DS_rospla/val',
                                          target_size = shape,
                                          batch_size = batch_size,
                                          class_mode = 'categorical',
                                          shuffle = False)

test_gen= test_datagen.flow_from_directory('/content/2DS_rospla/test/',
                                          target_size = shape,
                                          batch_size = batch_size,
                                          class_mode = 'categorical',
                                          shuffle = False)

num_class = test_gen.num_classes
label_class = train_gen.class_indices

print(label_class)



base_model = Xception(include_top=False, weights='imagenet', input_tensor=None, 
                      input_shape=input_size, pooling=max, classes=num_class,
                      classifier_activation='softmax')

# adding custom layers
model = Sequential()
model.add(base_model)
model.add(GlobalAveragePooling2D())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_class, activation = 'softmax'))

base_model.trainable = False

model.summary()

model.compile(optimizer = Adam(),
             loss="categorical_crossentropy",
             metrics=["acc"])

base_path = 'train_model'
trained_model_path = base_path + 'HVPS_model/'
model_names = trained_model_path + '.{epoch:02d}-{val_acc:.2f}.h5'

earlystopping = EarlyStopping(monitor ="val_loss", 
                              mode = "auto", patience = 15, 
                              restore_best_weights = True)

checkpoint = ModelCheckpoint(model_names, monitor = 'val_loss',
                             mode = 'auto', verbose = 1,
                             save_best_only = True)

history = model.fit(train_gen,
                    steps_per_epoch = len(train_gen),
                    validation_data = val_gen,
                    validation_steps = len(val_gen),
                    epochs = 100, verbose = 1, callbacks=[checkpoint, earlystopping])

from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing import image

plot_model(base_model, to_file='xception_model_2DS.jpg')

#Get the accuracy score
test_score = model.evaluate_generator(test_gen, 32)

print("[INFO] accuracy: {:.2f}%".format(test_score[1] * 100)) 
print("[INFO] Loss: ",test_score[0])

history.history['loss']
history.history['acc']

plt.plot(history.history['loss'], label = 'Training Loss')
plt.plot(history.history['val_loss'], label = 'Validation Loss')
plt.title('Training and Validation Loss')
plt.ylabel('value')
plt.xlabel('No. epoch')
plt.legend(loc = "upper left")
plt.show()

plt.plot(history.history['acc'], label = 'Training Accuracy')
plt.plot(history.history['val_acc'], label = 'Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.ylabel('value')
plt.xlabel('No. epoch')
plt.legend(loc="upper left")
plt.show()

#Plot the confusion matrix. Set Normalize = True/False

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.figure(figsize=(10,10))

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()

    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        cm = np.around(cm, decimals=2)
        cm[np.isnan(cm)] = 0.0
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

#Print the Target names

target_names = []
for key in train_gen.class_indices:
    target_names.append(key)

print(target_names)

from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import itertools

#Confution Matrix 

Y_pred = model.predict_generator(test_gen)
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')
cm = confusion_matrix(test_gen.classes, y_pred)
plot_confusion_matrix(cm, target_names, title='Confusion Matrix')

#Print Classification Report
print('Classification Report')
print(classification_report(test_gen.classes, y_pred, target_names=target_names))

#Save the model
model.save("Xception2DS_genra.hdf5")